{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(\"chgk/results.pkl\", \"rb\")) as openfile:\n",
    "    results = pickle.load(openfile)\n",
    "with (open(\"chgk/tournaments.pkl\", \"rb\")) as openfile:\n",
    "    tournaments = pickle.load(openfile)\n",
    "with (open(\"chgk/players.pkl\", \"rb\")) as openfile:\n",
    "    players = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tournaments = {}\n",
    "test_tournaments = {}\n",
    "for key, value in tournaments.items():\n",
    "    if len(results[key]) and 'mask' in results[key][0]:\n",
    "        if results[key][0]['mask'] != None: \n",
    "            if int(value['dateStart'].split('-')[0]) == 2019:\n",
    "                train_tournaments[key] = value\n",
    "            if int(value['dateStart'].split('-')[0]) == 2020:\n",
    "                test_tournaments[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем веса вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "weights = {}\n",
    "for idx, data in train_tournaments.items():\n",
    "    totalQs = np.sum(list(data['questionQty'].values()))\n",
    "    masks = []\n",
    "    for team in results[idx]:\n",
    "        if team['mask'] and len(team['mask']) == totalQs and 'X' not in team['mask'] and '?' not in team['mask']:\n",
    "            masks.append(list(map(int, team['mask'])))\n",
    "    weights[idx] = 1 - np.mean(masks, axis=0)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем таблицу игроков и вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for idx, data in train_tournaments.items():\n",
    "    totalQs = np.sum(list(data['questionQty'].values()))\n",
    "    \n",
    "    for team in results[idx]:\n",
    "        if team['mask'] and len(team['mask']) == totalQs and 'X' not in team['mask'] and '?' not in team['mask']:\n",
    "            mask = list(map(int, team['mask']))\n",
    "            for member in team[\"teamMembers\"]:\n",
    "                for iq in range(totalQs):\n",
    "                    df.append((member[\"player\"][\"id\"],\n",
    "                               weights[idx][iq],\n",
    "                               mask[iq],\n",
    "                               f\"{idx}_\"+str(iq))) \n",
    "df = pd.DataFrame(df, columns=[\"player\", \"difficult\", \"answer\", \"question_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>difficult</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.554113</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player  difficult  answer question_id\n",
       "0    6212   0.116883       1      4772_0\n",
       "1    6212   0.220779       1      4772_1\n",
       "2    6212   0.554113       1      4772_2\n",
       "3    6212   0.480519       1      4772_3\n",
       "4    6212   0.121212       1      4772_4"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "player_rating = {}\n",
    "all_players = df[\"player\"].unique()\n",
    "model = LogisticRegression(C=100, solver=\"lbfgs\")\n",
    "for player in all_players:\n",
    "    train = df[df[\"player\"]==player]\n",
    "    data_X = train[[\"difficult\"]]\n",
    "    data_y = train[\"answer\"]\n",
    "    if np.unique(data_y).shape[0] > 1:\n",
    "        model.fit(data_X, data_y)\n",
    "        predict = model.predict_proba(np.arange(0, 1, 0.01).reshape(-1, 1))[:, 1]\n",
    "        rating = predict @ density[0] * 0.01 # 0,01 - это шаг гистограммы\n",
    "    else:\n",
    "        rating = data_y.values[0]\n",
    "    player_rating[player] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"dataset.npy\", player_rating)\n",
    "player_rating = np.load(\"dataset.npy\", allow_pickle=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.mean(list(player_rating.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['player_rating'] = df['player'].apply(lambda x: player_rating[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>difficult</th>\n",
       "      <th>answer</th>\n",
       "      <th>question_id</th>\n",
       "      <th>player_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_0</td>\n",
       "      <td>0.707254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.220779</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_1</td>\n",
       "      <td>0.707254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.554113</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_2</td>\n",
       "      <td>0.707254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_3</td>\n",
       "      <td>0.707254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6212</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>4772_4</td>\n",
       "      <td>0.707254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   player  difficult  answer question_id  player_rating\n",
       "0    6212   0.116883       1      4772_0       0.707254\n",
       "1    6212   0.220779       1      4772_1       0.707254\n",
       "2    6212   0.554113       1      4772_2       0.707254\n",
       "3    6212   0.480519       1      4772_3       0.707254\n",
       "4    6212   0.121212       1      4772_4       0.707254"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "София Лебедева\n",
      "Давид Кан\n",
      "Михаил Завьялов\n",
      "София Савенко\n",
      "Алексей Антонов\n",
      "Александр Корнюков\n",
      "Полина Джегур\n",
      "Елизавета Коваленко\n",
      "Арина Гринко\n",
      "Юлия Крюкова\n",
      "Наталья Артемьева\n",
      "Екатерина Горелова\n",
      "Глеб Гаврилов\n",
      "Семён Зайдельман\n",
      "Дамир Тужушев\n",
      "Алибек Аубакиров\n",
      "Никита Романов\n",
      "Александр Полторак\n",
      "Никита Панфилов\n",
      "Вячеслав Маслянко\n",
      "Вадим Солодовников\n",
      "Артём Захаров\n",
      "Оксана Черенкова\n",
      "Андрей Козенко\n",
      "Дмитрий Вальтер\n",
      "Валентина Подюкова\n",
      "Елизавета Шкеда\n",
      "Лидия Подшивайлова\n",
      "Оганес Саакян\n",
      "Сабит Мамбетов\n",
      "Семён Кохоновер\n",
      "Ольга Кинзерская\n",
      "Илья Микулин\n",
      "Василий Погребной\n",
      "Константин Каволин\n",
      "Мария Маторная\n",
      "Елена Бровченко\n",
      "Иван Катруха\n",
      "Дмитрий Кудинов\n",
      "Светлана Обогрелова\n",
      "Максим Руссо\n",
      "Данута Дембовская\n",
      "Максим Ребров\n",
      "Лейсан Ибнеева\n",
      "Михаил Вантеев\n",
      "Елизавета Корначёва\n",
      "Александр Ковалевич\n",
      "Константин Шаталин\n",
      "Егор Лобынцев\n",
      "Серафим Рылов\n"
     ]
    }
   ],
   "source": [
    "ordered = dict(sorted(player_rating.items(), key=lambda item: -item[1]))\n",
    "\n",
    "def id2name(idx):\n",
    "    return players[idx][\"name\"] + \" \" + players[idx][\"surname\"]\n",
    "\n",
    "for i in range(50):\n",
    "    print(id2name(list(ordered.keys())[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def team_power(team):\n",
    "    mates = [mate[\"player\"][\"id\"] for mate in team]\n",
    "    result = 1\n",
    "    for mate in mates:\n",
    "        sub = avg\n",
    "        if mate in player_rating.keys():\n",
    "            sub = player_rating[mate]\n",
    "        result = result * (1 - sub)\n",
    "    result = 1 - result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman 0.6704974265515671\n",
      "kendall 0.5169115681490986\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, kendalltau\n",
    "\n",
    "\n",
    "spearman = []\n",
    "kendall = []\n",
    "for tournament in test_tournaments:\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for team in results[tournament]:\n",
    "        if 'position' in team and \\\n",
    "        'teamMembers' in team:\n",
    "            actual.append(1./team['position'])\n",
    "            predicted.append(team_power(team['teamMembers']))\n",
    "    spearman_coef = spearmanr(actual, predicted)[0]\n",
    "    kendall_coef = kendalltau(actual, predicted)[0]\n",
    "    \n",
    "    if not np.isnan(spearman_coef):\n",
    "        spearman.append(spearman_coef)\n",
    "    if not np.isnan(kendall_coef):\n",
    "        kendall.append(kendall_coef)\n",
    "        \n",
    "print(\"spearman\", np.mean(spearman))\n",
    "print(\"kendall\", np.mean(kendall))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
